# Airbnb Data Engineering Project (Snowflake + dbt)

## Overview

This project implements an end-to-end data engineering pipeline for
Airbnb datasets using Snowflake and dbt, following the Medallion
Architecture (Bronze â†’ Silver â†’ Gold). Raw data is ingested from AWS S3,
cleaned and standardized in dbt, and transformed into analytics-ready
models for downstream use.

## Pipeline Architecture

Data Flow: AWS S3 â†’ Snowflake Staging â†’ Bronze Layer â†’ Silver Layer â†’
Gold Layer â†’ Analytics

Technologies: - Snowflake (Data warehouse) - dbt Core (Transformations,
tests, snapshots) - AWS S3 (Raw data storage) - Python (Environment
setup) - SQL + Jinja

## Data Layers

### Bronze Layer (Raw)

- bronze_bookings
- bronze_hosts
- bronze_listings

### Silver Layer (Clean)

- silver_bookings
- silver_hosts
- silver_listings

### Gold Layer (Analytics)

- gold_fact
- gold_obt

### Snapshots (SCD Type-2)

- dim_hosts
- dim_listings
- dim_bookings

## Key Features

- Incremental dbt models for efficient processing
- Custom macros and Dynamic SQL generation
- SCD Type-2 snapshots for historical tracking
- Ephemeral models for optimized transformations
- Data quality testing (unique, not-null, relationships)
- Automatic lineage documentation via dbt

## ğŸ“ Project Structure

```
AWS_DBT_Snowflake/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ pyproject.toml                      # Python dependencies
â”œâ”€â”€ main.py                             # Main execution script
â”‚
â”œâ”€â”€ SourceData/                         # Raw CSV data files
â”‚   â”œâ”€â”€ bookings.csv
â”‚   â”œâ”€â”€ hosts.csv
â”‚   â””â”€â”€ listings.csv
â”‚
â”œâ”€â”€ DDL/                                # Database schema definitions
â”‚   â”œâ”€â”€ snowquery_ddl.sql                         # Table creation scripts
â”‚   â””â”€â”€ resources.sql
â”‚
â””â”€â”€ aws_dbt_snowflake_project/         # Main dbt project
    â”œâ”€â”€ dbt_project.yml                 # dbt project configuration
    â”œâ”€â”€ ExampleProfiles.yml             # Snowflake connection profile
    â”‚
    â”œâ”€â”€ models/                         # dbt models
    â”‚   â”œâ”€â”€ sources/
    â”‚   â”‚   â””â”€â”€ sources.yml             # Source definitions
    â”‚   â”œâ”€â”€ bronze/                     # Raw data layer
    â”‚   â”‚   â”œâ”€â”€ bronze_bookings.sql
    â”‚   â”‚   â”œâ”€â”€ bronze_hosts.sql
    â”‚   â”‚   â””â”€â”€ bronze_listings.sql
    â”‚   â”œâ”€â”€ silver/                     # Cleaned data layer
    â”‚   â”‚   â”œâ”€â”€ silver_bookings.sql
    â”‚   â”‚   â”œâ”€â”€ silver_hosts.sql
    â”‚   â”‚   â””â”€â”€ silver_listings.sql
    â”‚   â””â”€â”€ gold/                       # Analytics layer
    â”‚       â”œâ”€â”€ gold_fact.sql
    â”‚       â”œâ”€â”€ gold_obt.sql
    â”‚       â””â”€â”€ ephemeral/              # Temporary models
    â”‚           â”œâ”€â”€ bookings.sql
    â”‚           â”œâ”€â”€ hosts.sql
    â”‚           â””â”€â”€ listings.sql
    â”‚
    â”œâ”€â”€ macros/                         # Reusable SQL functions
    â”‚   â”œâ”€â”€ generate_schema_name.sql    # Custom schema naming
    â”‚   â”œâ”€â”€ multiply.sql                # Math operations
    â”‚   â”œâ”€â”€ tag.sql                     # Categorization logic
    â”‚   â””â”€â”€ trimmer.sql                 # String utilities
    â”‚
    â”œâ”€â”€ analyses/                       # Ad-hoc analysis queries
    â”‚   â”œâ”€â”€ explore.sql
    â”‚   â”œâ”€â”€ if_else.sql
    â”‚   â””â”€â”€ loop.sql
    â”‚
    â”œâ”€â”€ snapshots/                      # SCD Type 2 configurations
    â”‚   â”œâ”€â”€ dim_bookings.yml
    â”‚   â”œâ”€â”€ dim_hosts.yml
    â”‚   â””â”€â”€ dim_listings.yml
    â”‚
    â”œâ”€â”€ tests/                          # Data quality tests
    â”‚   â””â”€â”€ testing_source.sql
    â”‚
    â””â”€â”€ seeds/                          # Static reference data
```

### Installation

1. **Clone the Repository**
   ```bash
   git clone <repository-url>
   cd AWS_DBT_Snowflake
   ```

2. **Create Virtual Environment**
   ```bash
   python -m venv .venv
   .venv\Scripts\Activate.ps1  # Windows PowerShell
   # or
   source .venv/bin/activate    # Linux/Mac
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   # or using pyproject.toml
   pip install -e .
   ```

   **Core Dependencies:**
   - `dbt-core>=1.11.2`
   - `dbt-snowflake>=1.11.0`
   - `sqlfmt>=0.0.3`

4. **Configure Snowflake Connection**
   
   Create `~/.dbt/profiles.yml`:
   ```yaml
   aws_dbt_snowflake_project:
     outputs:
       dev:
         account: <your-account-identifier>
         database: AIRBNB
         password: <your-password>
         role: ACCOUNTADMIN
         schema: dbt_schema
         threads: 4
         type: snowflake
         user: <your-username>
         warehouse: COMPUTE_WH
     target: dev
   ```

5. **Set Up Snowflake Database**
   
   Run the DDL scripts to create tables:
   ```bash
   # Execute DDL/ddl.sql in Snowflake to create staging tables
   ```

6. **Load Source Data**
   
   Load CSV files from `SourceData/` to Snowflake staging schema:
   - `bookings.csv` â†’ `AIRBNB.STAGING.BOOKINGS`
   - `hosts.csv` â†’ `AIRBNB.STAGING.HOSTS`
   - `listings.csv` â†’ `AIRBNB.STAGING.LISTINGS`

## Business Use Cases

- Host performance analytics
- Listing & pricing intelligence
- Occupancy and seasonal trend analysis
- Customer booking behaviour analysis

## Future Improvements

- Add orchestration with Airflow or Prefect
- Add CI/CD pipeline for dbt
- Integrate Great Expectations for DQ
- Build BI dashboards (Tableau / Power BI)

## Author

Utsav D Kanani

